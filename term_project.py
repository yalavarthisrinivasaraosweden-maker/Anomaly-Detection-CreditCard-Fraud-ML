# -*- coding: utf-8 -*-
"""Term Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RxIgHN1QE9bbXyPVrc7_tYwJ5_ZmTacu
"""

# ===== CELL 1 — Setup =====
!pip install scikit-learn tensorflow imbalanced-learn

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.colors import LinearSegmentedColormap

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.model_selection import train_test_split

from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM

from tensorflow import keras
from tensorflow.keras import layers, models

# ===== CELL 2 — LOAD DATA =====
# Replace with the name of your uploaded file
df = pd.read_csv("/content/sample_data/creditcard.csv")


print(df.head())
print(df.shape)
print(df.info())

"""#"""

# ===== CELL 3 — DATA INSPECTION =====

print("Missing values:", df.isnull().sum().sum())
print(df["Class"].value_counts())

sns.countplot(x=df["Class"])
plt.title("Distribution of Normal vs Fraud (Anomaly)")
plt.show()

# Scale only numeric features
features = df.drop("Class", axis=1).values
scaler = StandardScaler()
X = scaler.fit_transform(features)
y = df["Class"].values

import pandas as pd
import matplotlib.pyplot as plt
import os

# Always re-create directory in the same cell
FIG_DIR = "/content/figures"
os.makedirs(FIG_DIR, exist_ok=True)

# ===============================
# Transaction Amount Distribution by Class
# ===============================
normal_amount = df[df["Class"] == 0]["Amount"]
fraud_amount = df[df["Class"] == 1]["Amount"]

plt.figure()
plt.boxplot(
    [normal_amount, fraud_amount],
    tick_labels=["Normal", "Fraud"],
    showfliers=False
)
plt.ylabel("Transaction Amount")
plt.title("Transaction Amount Distribution by Class")
plt.tight_layout()
plt.savefig(f"{FIG_DIR}/amount_boxplot.pdf")
plt.close()

# ===============================
# Correlation Heatmap of PCA Features
# ===============================
pca_features = [f"V{i}" for i in range(1, 29)]
corr_matrix = df[pca_features].corr()

plt.figure(figsize=(8, 6))
plt.imshow(corr_matrix)
plt.colorbar()
plt.title("Correlation Heatmap of PCA Features")
plt.xticks(range(len(pca_features)), pca_features, rotation=90)
plt.yticks(range(len(pca_features)), pca_features)
plt.tight_layout()
plt.savefig(f"{FIG_DIR}/correlation_heatmap.pdf")
plt.close()

print("FILES CREATED:")
print(f"{FIG_DIR}/amount_boxplot.pdf")
print(f"{FIG_DIR}/correlation_heatmap.pdf")

"""# **Z Score Outlier Detection**"""

# ===== Updated CELL 4 — Z-SCORE OUTLIER DETECTION =====

# If your file is inside Google Drive (recommended)


# Replace path below with the correct path location:
df = pd.read_csv("/content/sample_data/creditcard.csv")

# ---- Clean Missing Values ----
df = df.dropna()  # remove rows with NaN
df.reset_index(drop=True, inplace=True)

print("Data shape after cleaning:", df.shape)

# Separate features and label
if "Class" not in df.columns:
    raise ValueError("❌ ERROR: Dataset must contain a 'Class' column for anomaly labels.")

X = df.drop("Class", axis=1).values
y = df["Class"].values

# Standardize
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ---- Z-score Calculation ----
from scipy.stats import zscore
z_scores = np.abs(zscore(X_scaled))

threshold = 3  # typical Z-score threshold
z_pred = (z_scores > threshold).any(axis=1).astype(int)  # 1 = anomaly

print("\n===== Z-SCORE RESULTS =====")
print(classification_report(y, z_pred))
print("ROC AUC:", roc_auc_score(y, z_pred))

"""# **Z Score Outlier Detection CM**"""

# Plot the confusion matrix

colors = ['#CFEEF0', '#00777F']
custom_cmap = LinearSegmentedColormap.from_list('custom_cmap', colors)
cm = confusion_matrix(y, z_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, cmap=custom_cmap, fmt='g')

# Add labels, title, and axis ticks
plt.title('Confusion Matrix ')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])
plt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])
plt.show()

"""# **Isolation Forest**"""

# ===== CELL 5 — ISOLATION FOREST =====
iso = IsolationForest(contamination=0.002, random_state=42)
iso.fit(X)
y_pred_iso = iso.predict(X)
y_pred_iso = np.where(y_pred_iso == -1, 1, 0)

print("Isolation Forest:")
print(classification_report(y, y_pred_iso))
print("ROC AUC:", roc_auc_score(y, y_pred_iso))

"""# **Isolation Forest CM**"""

# Custom color palette
colors = ['#CFEEF0', '#00777F']
custom_cmap = LinearSegmentedColormap.from_list('custom_cmap', colors)

# Plot the confusion matrix
cm = confusion_matrix(y, y_pred_iso)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, cmap=custom_cmap, fmt='g')

# Add labels, title, and axis ticks
plt.title('Confusion Matrix ')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])
plt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])
plt.show()

"""# **One Class SVM**"""

ocsvm = OneClassSVM(kernel="linear", nu=0.002)
y_pred_svm = ocsvm.fit_predict(X)
y_pred_svm = np.where(y_pred_svm == -1, 1, 0)

print("Linear One-Class SVM:")
print(classification_report(y, y_pred_svm))
print("ROC AUC:", roc_auc_score(y, y_pred_svm))

"""# **One Class SVM CM**"""

# Plot the confusion matrix
cm = confusion_matrix(y, y_pred_svm)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, cmap=custom_cmap, fmt='g')

# Add labels, title, and axis ticks
plt.title('Confusion Matrix ')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])
plt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])
plt.show()

"""# **Autoencoder**"""

# ===== CELL 7 — AUTOENCODER =====

X_normal = X[y == 0]
X_train, X_test = train_test_split(X_normal, test_size=0.2, random_state=42)

input_dim = X_train.shape[1]

autoencoder = keras.Sequential([
    layers.Dense(16, activation="relu", input_shape=(input_dim,)),
    layers.Dense(8, activation="relu"),
    layers.Dense(16, activation="relu"),
    layers.Dense(input_dim, activation="linear")
])

autoencoder.compile(optimizer="adam", loss="mse")
autoencoder.summary()

history = autoencoder.fit(
    X_train, X_train,
    epochs=15,
    batch_size=256,
    validation_split=0.2,
    verbose=1
)

"""# **Autoencoder Evaluation**"""

# ===== CELL 8 — EVALUATION =====

reconstructions = autoencoder.predict(X)
mse = np.mean(np.square(X - reconstructions), axis=1)

threshold = np.percentile(mse, 99.5)
print("Autoencoder threshold:", threshold)

y_pred_ae = (mse > threshold).astype(int)

print("Autoencoder Results:")
print(classification_report(y, y_pred_ae))
print("ROC AUC:", roc_auc_score(y, y_pred_ae))

"""# **Autoencode CM**"""

# Plot the confusion matrix
cm = confusion_matrix(y, y_pred_ae)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, cmap=custom_cmap, fmt='g')

# Add labels, title, and axis ticks
plt.title('Confusion Matrix ')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])
plt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])
plt.show()

"""# **Comparsion**"""

# ===== CELL 9 — COMPARISON TABLE =====

results = {
    "Model": ["Z-score", "IsolationForest", "OneClassSVM", "Autoencoder"],
    "AUC ROC": [
        roc_auc_score(y, z_pred),
        roc_auc_score(y, y_pred_iso),
        roc_auc_score(y, y_pred_svm),
        roc_auc_score(y, y_pred_ae)
    ]
}

results_df = pd.DataFrame(results)
print(results_df)
sns.barplot(x="Model", y="AUC ROC", data=results_df)
plt.title("Anomaly Detection Model Comparison")
plt.show()